# LLM Personal Attribute Inference Using Small Models

- Note when running: to enable GPU acceleration when running models, modify the
  shell.nix file to use either:
  - ollama for CPU only
  - ollama-rocm for AMD GPU acceleration
  - ollama-cuda for Nvidia GPU acceleration

